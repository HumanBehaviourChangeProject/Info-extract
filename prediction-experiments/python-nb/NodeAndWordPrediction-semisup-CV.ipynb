{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-supervised Outcome value prediction from Behaviour Change Data\n",
    "\n",
    "In this notebook, we set up a regression/classification pipeline to predict the outcome value under a semi-supervised setting. The objective is to see if adding automatically extracted data can help improve the outcome value predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, getopt, os\n",
    "sys.path.insert(0, \"ov-predict/src/\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#external libs\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statistics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import backend as k\n",
    "from math import sqrt\n",
    "\n",
    "#our libraries\n",
    "from model.lstm import buildModel\n",
    "from model.lstm import rmse\n",
    "from preprocessing.InputHelper import InputHelper\n",
    "from preprocessing.InputHelper import mapToNonUniformlySpacedIntervals\n",
    "from preprocessing.InputHelper import transformLabels\n",
    "from common.utils import plotHistogram\n",
    "from common.utils import getSelectedData\n",
    "from common.utils import printWordVecs\n",
    "from common.utils import convertSoftmaxToLabels\n",
    "from common.utils import computePerIntervalStats\n",
    "from common.utils import computeTwoStagedRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Globals\n",
    "SEED = 314159\n",
    "NUM_EXPERIMENTS = 1\n",
    "MAXLEN=100\n",
    "FOLD=5\n",
    "NUM_EXPERIMENTS = 1\n",
    "EPOCHS = 3\n",
    "NUM_CLASSES=0\n",
    "\n",
    "DATAFILE=\"../../core/prediction/sentences/train.tsv\"\n",
    "NOISY_DATAFILE=\"../../core/prediction/sentences/train.noisy.tsv\"\n",
    "NODEVECFILE_REF=\"../../core/prediction/graphs/nodevecs/nodes_and_words_ref.vec\"\n",
    "NODEVECFILE_NOISY=\"../../core/prediction/graphs/nodevecs/nodes_and_words_extracted.vec\"\n",
    "MERGE_VEC_FILE = 'mergedvec.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep a dictionary (keyed by document name) of corresponding pairs of RCTArms (DataInstances)\n",
    "#e.g. for document study['ABC.pdf'] --> {ref-data, noisy-data}\n",
    "\n",
    "# the class def\n",
    "from datadef.rct import RCTArm\n",
    "from datadef.rct import RCTArms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeVecFiles(refVecFile, extractedVecFile, mergedFileName):\n",
    "    with open(refVecFile) as ref_f:\n",
    "        r_content = ref_f.readlines()\n",
    "\n",
    "    with open(extractedVecFile) as ext_f:\n",
    "        e_content = ext_f.readlines()\n",
    "    \n",
    "    totalwords = str(int(r_content[0].split(' ')[0]) + int(e_content[0].split(' ')[0]))\n",
    "    dim = r_content[0].split(' ')[1]\n",
    "    \n",
    "    header = totalwords + ' ' + dim\n",
    "    \n",
    "    with open(mergedFileName, 'w') as f:\n",
    "        f.write(header)\n",
    "        \n",
    "        for item in r_content[1:]:\n",
    "            f.write(\"%s\" % item)        \n",
    "        for item in e_content[1:]:\n",
    "            f.write(\"%s\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFold(fold_number, model, x_train, y_train, x_test, y_test, maxlen, num_classes, epochs):\n",
    "\n",
    "    x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
    "    x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)\n",
    "    BATCH_SIZE = 1\n",
    "\n",
    "    print (\"Training model...\")\n",
    "    model.fit(x_train, y_train,\n",
    "        epochs=epochs,\n",
    "        verbose=True,         \n",
    "        #validation_split=0.1,\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=True)\n",
    "    if (num_classes > 0):\n",
    "        print(\"Fold {}: Cross-entropy loss: {:.4f}, Accuracy: {:.4f}\".format(fold_number, loss, accuracy))\n",
    "    else:\n",
    "        print(\"Fold {}: Loss: {:.4f}, RMSE: {:.4f}\".format(fold_number, loss, accuracy))\n",
    "\n",
    "    '''\n",
    "    y_preds = model.predict(x_test)\n",
    "    y_preds = convertSoftmaxToLabels(y_preds)\n",
    "    \n",
    "    # in this part of the code use the true values (in case of classification) to predict values and compute rmse...\n",
    "    if ptype=='m':\n",
    "        # perform and evaluate 2-step regression... classify and then sample a value around the median from the interval\n",
    "        accuracy = computeTwoStagedRMSE(num_classes, fold_number, y_preds, y_train_vals, y_test_vals)\n",
    "    '''\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.lstm import create_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "import random\n",
    "\n",
    "class RCT_Ref_Noise_Pairs:\n",
    "    \n",
    "    def __init__(self, datafile, noisy_datafile):        \n",
    "        rct_ref_dict = self.loadData(datafile)\n",
    "        rct_noisy_dict = self.loadData(noisy_datafile)\n",
    "    \n",
    "        ref_keys = set(rct_ref_dict.keys())\n",
    "        noisy_keys = set(rct_noisy_dict.keys())\n",
    "        common_keys = ref_keys.intersection(noisy_keys)\n",
    "        \n",
    "        self.numinstances = len(common_keys)\n",
    "        self.rcts = {}\n",
    "        \n",
    "        for key in common_keys:\n",
    "            self.rcts[key] = [rct_ref_dict[key], rct_noisy_dict[key]]\n",
    "\n",
    "    def loadData(self, datafile):\n",
    "        rct_dict = {}    \n",
    "        rcts = RCTArms(datafile)\n",
    "        #rcts.convertWordsToIds()\n",
    "        \n",
    "        for rct in rcts.rcts:\n",
    "            rct_dict[rct.docname] = rct\n",
    "        return rct_dict\n",
    "\n",
    "    def printAllPairs(self):\n",
    "        for key in self.rcts:\n",
    "            print (key + ', ' + str(self.rcts[key][0]) + ', ' + str(self.rcts[key][1]))\n",
    "\n",
    "    def formXY(self, maxlen=50):        \n",
    "\n",
    "        all_text_ref = []\n",
    "        self.Y_ref = []\n",
    "        for key in self.rcts:\n",
    "            all_text_ref.append(self.rcts[key][0].text)\n",
    "            self.Y_ref.append(self.rcts[key][0].ov)\n",
    "            \n",
    "        all_text_noisy = []\n",
    "        self.Y_noisy = []\n",
    "        for key in self.rcts:\n",
    "            all_text_noisy.append(self.rcts[key][1].text)\n",
    "            self.Y_noisy.append(self.rcts[key][1].ov)\n",
    "        \n",
    "        self.keras_tokenizer = Tokenizer(num_words=None, filters=[], lower=False, split=' ')\n",
    "        \n",
    "        all_text = all_text_ref[:] # copy ref into all_text\n",
    "        all_text.extend(all_text_noisy)\n",
    "        \n",
    "        self.keras_tokenizer.fit_on_texts(all_text)\n",
    "        \n",
    "        self.vsize = len(self.keras_tokenizer.word_index) + 1\n",
    "        \n",
    "        self.X_ref = self.keras_tokenizer.texts_to_sequences(all_text_ref)\n",
    "        self.X_ref = pad_sequences(self.X_ref, padding='post', maxlen=50)        \n",
    "        self.X_noisy = self.keras_tokenizer.texts_to_sequences(all_text_ref)\n",
    "        self.X_noisy = pad_sequences(self.X_noisy, padding='post', maxlen=50)\n",
    "        \n",
    "        self.X_ref_array = np.asarray(self.X_ref)\n",
    "        self.Y_ref_array = np.asarray(self.Y_ref, dtype=np.float64)\n",
    "\n",
    "    # Choose random indexes from train_indexes and replace the ref data with noise\n",
    "    # For baseline for the noise injection experiments, we use only\n",
    "    # a fraction of the clean data (as given by the SNR). The noise in this case is 0,\n",
    "    # i.e., no additional data is provided as input.\n",
    "    def getXYForFold(self, train_indexes, test_indexes, snr, clean_indexes=None):\n",
    "        num_clean_instances = int(snr * len(train_indexes))\n",
    "        clean_indexes_map = {}\n",
    "        include_noise = False\n",
    "        \n",
    "        if clean_indexes==None:\n",
    "            clean_indexes = random.choices(train_indexes, k=num_clean_instances)\n",
    "            include_noise = True\n",
    "            \n",
    "        for i in clean_indexes:\n",
    "            clean_indexes_map[i] = i\n",
    "        \n",
    "        X_train = []\n",
    "        X_test = []\n",
    "        Y_train = []\n",
    "        Y_test = []\n",
    "        \n",
    "        for index in train_indexes:\n",
    "            if index in clean_indexes_map:\n",
    "                X_train.append(self.X_ref[index])\n",
    "                Y_train.append(self.Y_ref[index])\n",
    "            elif include_noise:\n",
    "                X_train.append(self.X_noisy[index])\n",
    "                Y_train.append(self.Y_noisy[index])\n",
    "            \n",
    "        for index in test_indexes:\n",
    "            X_test.append(self.X_ref[index])\n",
    "            Y_test.append(self.Y_ref[index])\n",
    "            \n",
    "        return X_train, Y_train, X_test, Y_test, clean_indexes\n",
    "        \n",
    "    def runCrossFoldExperiment(self, model, n_splits, snr, MAXLEN, NUM_CLASSES, epochs=20):\n",
    "        self.formXY(MAXLEN)  # get the data in XY form\n",
    "        avg_over_experiments = 0\n",
    "        avg_over_experiments_baseline = 0\n",
    "        \n",
    "        for i in range (0, NUM_EXPERIMENTS):        \n",
    "            fold_info = KFold(n_splits=n_splits, random_state=SEED)\n",
    "            \n",
    "            n = 0\n",
    "            avg_metric_value = 0\n",
    "            baseline_metric_value = 0 # only with clean data\n",
    "            \n",
    "            for train_indexes, test_indexes in fold_info.split(self.X_ref_array, self.Y_ref_array):                \n",
    "                X_train, Y_train, X_test, Y_test, clean_indexes = self.getXYForFold(train_indexes, test_indexes, snr, None)\n",
    "                \n",
    "                print (\"|train_with_noise| = {}, |test| = {}\".format(len(X_train), len(X_test)))\n",
    "                \n",
    "                Y_train, Y_test = transformLabels(Y_train, Y_test, NUM_CLASSES, useMedians=True)                \n",
    "                avg_metric_value += processFold(n, model, X_train, Y_train, X_test, Y_test, MAXLEN, NUM_CLASSES, epochs)\n",
    "\n",
    "                #baseline with only true data (subset given by snr)\n",
    "                X_train, Y_train, X_test, Y_test, clean_indexes = self.getXYForFold(train_indexes, test_indexes, snr, clean_indexes)\n",
    "                \n",
    "                print (\"|train_refonly| = {}, |test| = {}\".format(len(X_train), len(X_test)))\n",
    "                \n",
    "                Y_train, Y_test = transformLabels(Y_train, Y_test, NUM_CLASSES, useMedians=True)                \n",
    "                baseline_metric_value += processFold(n, model, X_train, Y_train, X_test, Y_test, MAXLEN, NUM_CLASSES, epochs)\n",
    "                \n",
    "                n += 1 # next fold\n",
    "                \n",
    "            avg_metric_value /= n\n",
    "            baseline_metric_value /= n\n",
    "            \n",
    "            avg_over_experiments += avg_metric_value\n",
    "            avg_over_experiments_baseline += baseline_metric_value\n",
    "            \n",
    "        return avg_over_experiments_baseline/NUM_EXPERIMENTS, avg_over_experiments/NUM_EXPERIMENTS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(DATAFILE, NOISY_DATAFILE, NODEVECFILE_REF, NODEVECFILE_NOISY, NUM_CLASSES, SNR):\n",
    "    \n",
    "    mergeVecFiles(NODEVECFILE_REF, NODEVECFILE_NOISY, MERGE_VEC_FILE)\n",
    "    inpH = InputHelper()\n",
    "    inpH.convertWordsToIds(MERGE_VEC_FILE)\n",
    "    \n",
    "    inpH.loadW2V(MERGE_VEC_FILE)\n",
    "    \n",
    "    ref_noise_pairs = RCT_Ref_Noise_Pairs(DATAFILE, NOISY_DATAFILE) \n",
    "    #ref_noise_pairs.printAllPairs()\n",
    "    \n",
    "    #create model\n",
    "    model = create_model(inpH, NUM_CLASSES, MAXLEN)\n",
    "    \n",
    "    baseline, eval_metric_val = ref_noise_pairs.runCrossFoldExperiment(model, FOLD, SNR, MAXLEN, NUM_CLASSES, epochs=EPOCHS) \n",
    "    print (\"SNR: {}, Baseline: {}, With-Extracted: {}\".format(SNR, baseline, eval_metric_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting node names...\n",
      "Collected node names...\n",
      "Converting words to ids...\n",
      "Finished converting words to ids...\n",
      "Loading W2V data...\n",
      "loaded word2vec for 31173 nodes\n",
      "1 words out of 31174 not found\n",
      "DEBUG: shape of embedding: (31174, 333)\n",
      "DEBUG: include_wordvecs = False\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 333)          10380942  \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 128)               203776    \n",
      "_________________________________________________________________\n",
      "output_vals (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,584,847\n",
      "Trainable params: 203,905\n",
      "Non-trainable params: 10,380,942\n",
      "_________________________________________________________________\n",
      "|train_with_noise| = 51, |test| = 13\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hbcp-predict-api/lib/python3.6/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "51/51 [==============================] - 10s 196ms/step - loss: 11.7662 - rmse: 11.7662\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 9s 170ms/step - loss: 11.2996 - rmse: 11.2996\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 9s 172ms/step - loss: 11.3466 - rmse: 11.3466\n",
      "13/13 [==============================] - 1s 41ms/step\n",
      "Fold 0: Loss: 12.2749, RMSE: 12.2749\n",
      "|train_refonly| = 16, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 6.6033 - rmse: 6.6033\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 6.5051 - rmse: 6.5051\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 6.3965 - rmse: 6.3965\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 0: Loss: 12.7575, RMSE: 12.7575\n",
      "|train_with_noise| = 51, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 12.4882 - rmse: 12.4882\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 12.4526 - rmse: 12.4526\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 12.4157 - rmse: 12.4157\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 1: Loss: 7.3964, RMSE: 7.3964\n",
      "|train_refonly| = 16, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 7.7650 - rmse: 7.7650\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 7.6427 - rmse: 7.6427\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 7.5159 - rmse: 7.5159\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 1: Loss: 7.3819, RMSE: 7.3819\n",
      "|train_with_noise| = 51, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "51/51 [==============================] - 9s 183ms/step - loss: 12.3535 - rmse: 12.3534\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 9s 177ms/step - loss: 12.0698 - rmse: 12.0698\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 9s 177ms/step - loss: 12.0003 - rmse: 12.0003\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 2: Loss: 7.3329, RMSE: 7.3329\n",
      "|train_refonly| = 16, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 12.9583 - rmse: 12.9583\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 12.8624 - rmse: 12.8624\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 12.7579 - rmse: 12.7579\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 2: Loss: 7.5393, RMSE: 7.5393\n",
      "|train_with_noise| = 51, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 12.2052 - rmse: 12.2052\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 9s 179ms/step - loss: 12.2991 - rmse: 12.2991\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 12.0303 - rmse: 12.0303\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 3: Loss: 18.0763, RMSE: 18.0763\n",
      "|train_refonly| = 17, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 9.8620 - rmse: 9.8620\n",
      "Epoch 2/3\n",
      "17/17 [==============================] - 3s 177ms/step - loss: 9.5249 - rmse: 9.5249\n",
      "Epoch 3/3\n",
      "17/17 [==============================] - 3s 177ms/step - loss: 9.3045 - rmse: 9.3045\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 3: Loss: 17.8730, RMSE: 17.8730\n",
      "|train_with_noise| = 52, |test| = 12\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "52/52 [==============================] - 10s 183ms/step - loss: 9.6824 - rmse: 9.6824\n",
      "Epoch 2/3\n",
      "52/52 [==============================] - 9s 180ms/step - loss: 9.5003 - rmse: 9.5003\n",
      "Epoch 3/3\n",
      "52/52 [==============================] - 9s 180ms/step - loss: 9.1709 - rmse: 9.1709\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "Fold 4: Loss: 18.1601, RMSE: 18.1601\n",
      "|train_refonly| = 16, |test| = 12\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 4.0881 - rmse: 4.0881\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 3.8152 - rmse: 3.8152\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 3.4935 - rmse: 3.4935\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "Fold 4: Loss: 18.6947, RMSE: 18.6947\n",
      "SNR: 0.4, Baseline: 12.84926462173462, With-Extracted: 12.648112583160401\n",
      "Collecting node names...\n",
      "Collected node names...\n",
      "Converting words to ids...\n",
      "Finished converting words to ids...\n",
      "Loading W2V data...\n",
      "loaded word2vec for 31173 nodes\n",
      "1 words out of 31174 not found\n",
      "DEBUG: shape of embedding: (31174, 333)\n",
      "DEBUG: include_wordvecs = False\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 333)          10380942  \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 128)               203776    \n",
      "_________________________________________________________________\n",
      "output_vals (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,584,847\n",
      "Trainable params: 203,905\n",
      "Non-trainable params: 10,380,942\n",
      "_________________________________________________________________\n",
      "|train_with_noise| = 51, |test| = 13\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hbcp-predict-api/lib/python3.6/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "51/51 [==============================] - 10s 203ms/step - loss: 13.7505 - rmse: 13.7505\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 9s 179ms/step - loss: 12.5503 - rmse: 12.5503\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 9s 179ms/step - loss: 12.4158 - rmse: 12.4158\n",
      "13/13 [==============================] - 1s 41ms/step\n",
      "Fold 0: Loss: 12.0331, RMSE: 12.0331\n",
      "|train_refonly| = 22, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 9.8148 - rmse: 9.8148\n",
      "Epoch 2/3\n",
      "22/22 [==============================] - 4s 180ms/step - loss: 9.7843 - rmse: 9.7843\n",
      "Epoch 3/3\n",
      "22/22 [==============================] - 4s 186ms/step - loss: 9.7222 - rmse: 9.7222\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "Fold 0: Loss: 11.9458, RMSE: 11.9458\n",
      "|train_with_noise| = 51, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 12.0659 - rmse: 12.0659\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 11.7706 - rmse: 11.7706\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 9s 179ms/step - loss: 12.0786 - rmse: 12.0786\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 1: Loss: 7.6352, RMSE: 7.6352\n",
      "|train_refonly| = 18, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 5.7629 - rmse: 5.7629\n",
      "Epoch 2/3\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 5.6972 - rmse: 5.6972\n",
      "Epoch 3/3\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 5.6752 - rmse: 5.6752\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 1: Loss: 7.5002, RMSE: 7.5002\n",
      "|train_with_noise| = 51, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "51/51 [==============================] - 9s 179ms/step - loss: 15.1280 - rmse: 15.1280\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 15.0058 - rmse: 15.0058\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 9s 179ms/step - loss: 15.0393 - rmse: 15.0393\n",
      "13/13 [==============================] - 0s 5ms/step\n",
      "Fold 2: Loss: 7.0186, RMSE: 7.0186\n",
      "|train_refonly| = 15, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 3s 183ms/step - loss: 13.4884 - rmse: 13.4884\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 3s 181ms/step - loss: 13.3858 - rmse: 13.3858\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 3s 182ms/step - loss: 13.3125 - rmse: 13.3125\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 2: Loss: 7.0108, RMSE: 7.0108\n",
      "|train_with_noise| = 51, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "51/51 [==============================] - 9s 184ms/step - loss: 13.7096 - rmse: 13.7096\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 9s 182ms/step - loss: 13.8376 - rmse: 13.8376\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 13.7846 - rmse: 13.7846\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 3: Loss: 17.9191, RMSE: 17.9191\n",
      "|train_refonly| = 20, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 10.8952 - rmse: 10.8952\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 12.3075 - rmse: 12.3075\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 11.3179 - rmse: 11.3179\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 3: Loss: 19.6736, RMSE: 19.6736\n",
      "|train_with_noise| = 52, |test| = 12\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "52/52 [==============================] - 9s 181ms/step - loss: 11.0145 - rmse: 11.0145\n",
      "Epoch 2/3\n",
      "52/52 [==============================] - 9s 182ms/step - loss: 10.8686 - rmse: 10.8686\n",
      "Epoch 3/3\n",
      "52/52 [==============================] - 9s 178ms/step - loss: 10.6437 - rmse: 10.6437\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "Fold 4: Loss: 18.8276, RMSE: 18.8276\n",
      "|train_refonly| = 21, |test| = 12\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "21/21 [==============================] - 4s 183ms/step - loss: 8.8250 - rmse: 8.8250\n",
      "Epoch 2/3\n",
      "21/21 [==============================] - 4s 184ms/step - loss: 8.5992 - rmse: 8.5992\n",
      "Epoch 3/3\n",
      "21/21 [==============================] - 4s 181ms/step - loss: 8.1164 - rmse: 8.1164\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "Fold 4: Loss: 18.2804, RMSE: 18.2804\n",
      "SNR: 0.5, Baseline: 12.88214340209961, With-Extracted: 12.68670301437378\n",
      "Collecting node names...\n",
      "Collected node names...\n",
      "Converting words to ids...\n",
      "Finished converting words to ids...\n",
      "Loading W2V data...\n",
      "loaded word2vec for 31173 nodes\n",
      "1 words out of 31174 not found\n",
      "DEBUG: shape of embedding: (31174, 333)\n",
      "DEBUG: include_wordvecs = False\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 100, 333)          10380942  \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 128)               203776    \n",
      "_________________________________________________________________\n",
      "output_vals (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,584,847\n",
      "Trainable params: 203,905\n",
      "Non-trainable params: 10,380,942\n",
      "_________________________________________________________________\n",
      "|train_with_noise| = 51, |test| = 13\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hbcp-predict-api/lib/python3.6/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "51/51 [==============================] - 11s 209ms/step - loss: 10.5366 - rmse: 10.5366\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 9s 182ms/step - loss: 9.6408 - rmse: 9.6408\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 9.6958 - rmse: 9.6958\n",
      "13/13 [==============================] - 1s 43ms/step\n",
      "Fold 0: Loss: 12.4093, RMSE: 12.4093\n",
      "|train_refonly| = 23, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "23/23 [==============================] - 4s 172ms/step - loss: 6.0626 - rmse: 6.0626\n",
      "Epoch 2/3\n",
      "23/23 [==============================] - 4s 179ms/step - loss: 5.8931 - rmse: 5.8931\n",
      "Epoch 3/3\n",
      "23/23 [==============================] - 4s 179ms/step - loss: 5.7565 - rmse: 5.7565\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 0: Loss: 12.9142, RMSE: 12.9142\n",
      "|train_with_noise| = 51, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 12.9988 - rmse: 12.9988\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 9s 179ms/step - loss: 12.7612 - rmse: 12.7612\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 12.6880 - rmse: 12.6880\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 1: Loss: 8.1645, RMSE: 8.1645\n",
      "|train_refonly| = 21, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "21/21 [==============================] - 4s 179ms/step - loss: 9.5557 - rmse: 9.5557\n",
      "Epoch 2/3\n",
      "21/21 [==============================] - 4s 177ms/step - loss: 9.2490 - rmse: 9.2490\n",
      "Epoch 3/3\n",
      "21/21 [==============================] - 4s 178ms/step - loss: 9.0485 - rmse: 9.0485\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 1: Loss: 7.2003, RMSE: 7.2003\n",
      "|train_with_noise| = 51, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "51/51 [==============================] - 9s 182ms/step - loss: 11.6649 - rmse: 11.6649\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 9s 182ms/step - loss: 11.6353 - rmse: 11.6353\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 11.4612 - rmse: 11.4612\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 2: Loss: 7.1085, RMSE: 7.1085\n",
      "|train_refonly| = 20, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 9.5008 - rmse: 9.5008\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 8.6572 - rmse: 8.6572\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 4s 181ms/step - loss: 8.1573 - rmse: 8.1573\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 2: Loss: 7.7964, RMSE: 7.7964\n",
      "|train_with_noise| = 51, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "51/51 [==============================] - 10s 189ms/step - loss: 10.6031 - rmse: 10.6031\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 9s 184ms/step - loss: 11.1378 - rmse: 11.1378\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 10s 188ms/step - loss: 10.2794 - rmse: 10.2794\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 3: Loss: 17.0026, RMSE: 17.0026\n",
      "|train_refonly| = 25, |test| = 13\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "25/25 [==============================] - 5s 184ms/step - loss: 8.4387 - rmse: 8.4387\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 5s 188ms/step - loss: 9.2661 - rmse: 9.2661\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 5s 186ms/step - loss: 8.8817 - rmse: 8.8817\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Fold 3: Loss: 16.9287, RMSE: 16.9287\n",
      "|train_with_noise| = 52, |test| = 12\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "52/52 [==============================] - 10s 183ms/step - loss: 9.8997 - rmse: 9.8997\n",
      "Epoch 2/3\n",
      "52/52 [==============================] - 9s 183ms/step - loss: 9.7727 - rmse: 9.7727\n",
      "Epoch 3/3\n",
      "52/52 [==============================] - 9s 178ms/step - loss: 9.4335 - rmse: 9.4335\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "Fold 4: Loss: 17.5149, RMSE: 17.5149\n",
      "|train_refonly| = 21, |test| = 12\n",
      "Training model...\n",
      "Epoch 1/3\n",
      "21/21 [==============================] - 4s 178ms/step - loss: 6.4415 - rmse: 6.4415\n",
      "Epoch 2/3\n",
      "21/21 [==============================] - 4s 185ms/step - loss: 5.2584 - rmse: 5.2584\n",
      "Epoch 3/3\n",
      "21/21 [==============================] - 4s 180ms/step - loss: 4.8862 - rmse: 4.8862\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "Fold 4: Loss: 16.7974, RMSE: 16.7974\n",
      "SNR: 0.6, Baseline: 12.32738618850708, With-Extracted: 12.439953994750976\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #main(sys.argv[1:])\n",
    "    for SNR in [0.4, 0.5, 0.6]:\n",
    "        process(DATAFILE, NOISY_DATAFILE, NODEVECFILE_REF, NODEVECFILE_NOISY, NUM_CLASSES, SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
